import hashlib
import json
from datetime import datetime
from typing import List, Optional
import logging
from pathlib import Path

logger = logging.getLogger(__name__)


class TimelineMemory:
    """
    M√©moire persistante pour la timeline en JSON local
    Supporte les conversations isol√©es
    """

    def __init__(self, conversation_id: str = None, storage_file: str = None):
        """
        Args:
            conversation_id: ID de la conversation (pour timeline isol√©e)
            storage_file: Chemin custom du fichier (optionnel)
        """
        if storage_file:
            # Chemin explicite fourni
            self.storage_file = Path(storage_file)
        elif conversation_id:
            # Timeline li√©e √† une conversation
            self.storage_file = Path(f"data/conversations/{conversation_id}/timeline_events.json")
        else:
            # Fallback : fichier global
            self.storage_file = Path("data/timeline_events.json")

        self.storage_file.parent.mkdir(parents=True, exist_ok=True)

        # Charger les √©v√©nements existants
        self.events_db = self._load_from_file()

        logger.info(f"‚úÖ TimelineMemory initialis√©e: {len(self.events_db)} √©v√©nements")

        # Compatibilit√© avec le code existant
        self.collection_id = conversation_id or "global"
        self.collection_name = f"timeline_{conversation_id}" if conversation_id else "timeline_global"

    def _load_from_file(self) -> dict:
        """Charger les √©v√©nements depuis le fichier JSON"""
        if not self.storage_file.exists():
            logger.info(f"Cr√©ation nouveau fichier: {self.storage_file}")
            return {}

        try:
            with open(self.storage_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"Charg√© {len(data)} √©v√©nements depuis {self.storage_file}")
            return data
        except Exception as e:
            logger.error(f"Erreur lecture fichier: {e}")
            return {}

    def _save_to_file(self):
        """Sauvegarder les √©v√©nements dans le fichier JSON"""
        try:
            with open(self.storage_file, 'w', encoding='utf-8') as f:
                json.dump(self.events_db, f, ensure_ascii=False, indent=2)
            logger.debug(f"üíæ Sauvegarde r√©ussie: {len(self.events_db)} √©v√©nements")
        except Exception as e:
            logger.error(f"Erreur sauvegarde fichier: {e}")

    def _hash_event(self, event) -> str:
        """G√©n√©rer un ID unique pour l'√©v√©nement"""
        date_str = event.date.isoformat() if isinstance(event.date, datetime) else str(event.date)
        key = f"{date_str}-{event.title}"
        return hashlib.sha256(key.encode()).hexdigest()

    def _event_to_dict(self, event) -> dict:
        """Convertir un √©v√©nement en dictionnaire JSON"""
        date_str = event.date.isoformat() if isinstance(event.date, datetime) else str(event.date)

        return {
            "date": date_str,
            "title": event.title,
            "source": getattr(event, "source", "unknown"),
            "event_type": getattr(event, "event_type", "unknown"),
            "description": getattr(event, "description", ""),
            "score": getattr(event, "score", 0.0),
            "timestamp": datetime.utcnow().isoformat()
        }

    # -------------------------------------------------
    # OPERATIONS
    # -------------------------------------------------

    def upsert_event(self, event):
        """Ajouter ou mettre √† jour un √©v√©nement"""

        event_id = self._hash_event(event)

        # V√©rifier si existe d√©j√†
        if event_id in self.events_db:
            logger.debug(f"√âv√©nement existe d√©j√†: {event.title}")
            return

        # Ajouter au dictionnaire
        self.events_db[event_id] = self._event_to_dict(event)

        # Sauvegarder imm√©diatement
        self._save_to_file()

        logger.info(f"‚úÖ √âv√©nement ajout√©: {event.title}")

    def load_all_events(self) -> List:
        """Charger tous les √©v√©nements"""
        events = []

        for event_id, event_data in self.events_db.items():
            events.append({
                "payload": event_data
            })

        logger.info(f"üìö Charg√© {len(events)} √©v√©nements depuis JSON")
        return events

    def similar_exists(self, event, threshold: float = 0.85) -> bool:
        """
        V√©rifier si un √©v√©nement similaire existe d√©j√†
        Version simplifi√©e : comparaison exacte sur hash
        (pas de recherche s√©mantique comme Albert)
        """
        event_id = self._hash_event(event)
        exists = event_id in self.events_db

        if exists:
            logger.debug(f"Doublon d√©tect√©: {event.title}")

        return exists

    # -------------------------------------------------
    # ADMIN
    # -------------------------------------------------

    def clear_all(self) -> bool:
        """Supprimer tous les √©v√©nements"""
        count = len(self.events_db)
        self.events_db.clear()
        self._save_to_file()
        logger.info(f"üóëÔ∏è Supprim√© {count} √©v√©nements")
        return True

    def get_stats(self) -> dict:
        """Obtenir des statistiques"""
        return {
            "total_events": len(self.events_db),
            "collection_id": self.collection_id,
            "collection_name": self.collection_name,
            "storage_file": str(self.storage_file),
            "storage_type": "local_json"
        }

    def export_to_json(self, filepath: str) -> bool:
        """Exporter tous les √©v√©nements vers un fichier JSON"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.events_db, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Export r√©ussi vers {filepath}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur export: {e}")
            return False

    def import_from_json(self, filepath: str) -> bool:
        """Importer des √©v√©nements depuis un fichier JSON"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                imported_data = json.load(f)

            # Fusionner avec les √©v√©nements existants
            self.events_db.update(imported_data)
            self._save_to_file()

            logger.info(f"‚úÖ Import r√©ussi: {len(imported_data)} √©v√©nements")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur import: {e}")
            return False
